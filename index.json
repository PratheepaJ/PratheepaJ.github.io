[{"authors":[],"categories":[],"content":"  Methods Integrating spatil targeted proteomics data  Derive features to represent spatial proximities of two spatil point processes  Methods to learning from spatial transcriptomics data from visual cortex   Applciation Predict the survival of breast cancer patients based on tumor-immune environment   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630899299,"objectID":"f7608f1b328992390bea1752f73cf175","permalink":"https://PratheepaJ.github.io/project/spatial-multiomics/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/spatial-multiomics/","section":"project","summary":"Methods for analyzing cellular, molecular, and spatial data.","tags":[],"title":"Spatial multi-omics","type":"project"},{"authors":[],"categories":[],"content":"  Methods Container Microbiome multi-omics includes maker-gene sequencing, metagenomics, metatranscriptomics, metabolomics, and cytokines. A container build from SummarizeExperiment class in Bioconductor can facilitate microbiome multi-omics integrative approaches.\n Transformation Transformation and imputation methods are needed to explore microbiome multi-omics.\n Metatranscriptomics and marker-gene integration   Applications Vaginal microbiome data  Integrative human microbiome project   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630899138,"objectID":"bdc29b4547574d181d3ad011c12d11d6","permalink":"https://PratheepaJ.github.io/project/micro-multiomics/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/micro-multiomics/","section":"project","summary":"Methods for analyzing microbiome multi-omics.","tags":[],"title":"Microbiome multi-omics","type":"project"},{"authors":[],"categories":[],"content":"  Methods Differential topic analysis In microbiome research, an important goal is often to find taxonomic differences across environments or groups. We introduce differential topic analysis that facilitates inferences on latent microbial communities.\n Software  R package is available in Github: diffTop Tutorial is available at diffTop  Papers and Preprint  A Statistical Perspective on the Challenges in Molecular Microbial Biology, Journal of Agricultural, Biological and Environmental Statistics.  Talks  BioC 2021, August 4, 2021. Slides. R-Ladies Dallas, July 12, 2021. Slides. International Conference on Environmental and Medical Statistics, January 9, 2020.    DNA contamination removal in molecular microbial studies Molecular technologies can quantify bacteria in low biomass samples, such as blood. However, DNA contamination from external sources misidentifies the taxon’s provenance. We developed a Bayesian reference analysis to infer DNA contamination.\n Software  R package is available in Github: BARBI. Tutorial is available at BARBI.  Papers and Preprint  Method paper (To be submitted).  Talks  Statistics Seminar, Department of Statistics, Stanford University - June 2, 2020. 21st Meeting of New Researchers in Statistics and Probability - July 24-27, 2019. 3rd Workshop on Statistical and Algorithmic Challenges in Microbiome Data Analysis - April 2, 2019.    Inference on longitudinal microbiome data Longitudinal designs help experimenters overcome some of the difficulties caused by the temporal and subject-to-subject variability of the microbiome. They also allow subjects to be used as their own controls.\nThe proposed resampling method combined moving block bootstrap (MBB) method, empirical subsampling method, mixture model, generalized linear model, generalized estimating equation, median-ratio method, and shrinkage estimation to enabling inference on microbiome longitudinal data. With the optimal block size computed using subsampling, the MBB method accounts for within-subject dependency by using overlapping blocks of repeated observations within each subject to draw valid inferences based on approximately pivotal statistic.\n Software  R package is available in Github: bootLong Tutorial is available at bootLong  Papers and Preprint  The Block Bootstrap Method for Longitudinal Microbiome Data, Stat arXiv.  Talks  Biomedical Computation at Stanford 2018, April 19, 2018.     Applications diffTop  In progress…   BARBI  Application to identify translocation of bacteria (To be submitted) Combined use of metagenomic sequencing and host response profiling for the diagnosis of suspected sepsis. BioRxiv   BootLong  Identify deferentially abundant taxa in preterm and term labor (vaginal microbiome data).    ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630898684,"objectID":"5148c92fe1b810c5c039a99241371965","permalink":"https://PratheepaJ.github.io/project/micro/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/micro/","section":"project","summary":"Methods for analyzing marker-gene and shotgun metagenomics data.","tags":[],"title":"Molecular microbial data analysis","type":"project"},{"authors":[],"categories":[],"content":"  Wang (1990) devised an analytical approximation for the bivariate CDF for a rectangular set using the Lugannani and Rice (1980) formula and the standard bivariate normal distribution. We considered the theoretical study of the saddlepoint approximation for the bivariate distributions and provided necessary corrections and clarifications for the formula established by Wang (1990).\nThe numerical methods are used to compute the probability when the set is non-rectangular. There are many applications where inferences on a particular parameter \\(\\theta_{1}\\) in the presence of other \\(k-1\\) parameters are necessary. Obtaining a marginal probability distribution for \\(\\hat{\\theta}_{1}\\) is a straightforward matter of letting the arguments corresponding to the remaining parameters approach infinite values in the joint CDF of \\(k\\) estimators. In order to approximate the joint CDF of estimators, we consider a class of problems in which the estimators \\(\\left[\\hat{\\theta}_{1}, \\ldots, \\hat{\\theta}_{k}\\right]^{T}\\) may be determined as the roots of \\(k\\) distinct estimating equations.\nApplication We can construct a joint confidence region for multi-dimensional parameters.\n Method First, we derive estimating equations as a vector of quadratic forms in normal random variables. Then, we identify the moment-generating function of quadratic forms in a normal random variable. Next, we derive the necessary and sufficient conditions to approximate the CDF of estimators via estimating equations. Finally, we invert the CDF of estimators to construct a joint confidence region.\n Software  PhD dissertation Chapter I, section 1.2 supplement.   Paper  PhD dissertation Chapter I, section 1.2.   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630896491,"objectID":"b4ee45b03189250f0af95858a1918e13","permalink":"https://PratheepaJ.github.io/project/mspbb/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/mspbb/","section":"project","summary":"Deriving a class of statistical methods, bivariate SPBB which is an indirect method to construct a confidence region for the parameter(s) of interest.","tags":[],"title":"Multivariate Saddlepoint-Based Bootstrap Method (MSPBB)","type":"project"},{"authors":[],"categories":[],"content":"  We identify the expression for the variable that was not defined in Wang (1990) to approximate the bivariate distributions.\nApplication Construct confidence interval by inverting joint distribution of the estimators (MSPBB).\n Method Wang (1990) derived the saddlepoint approximation for bivariate distributions using the saddlepoint approximation for distribution (Lugannani \u0026amp; Rice, 1980) and standard bivariate normal distribution. We used complex analysis to derive the expression for the variable that was not defined in Wang (1990) to approximate the bivariate distributions.\n Software  PhD dissertation Chapter I, section 1.3 supplement.   Paper  PhD dissertation Chapter I, section 1.3.   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630895916,"objectID":"ea443e0abbab6521b5b12c3fa0681aa1","permalink":"https://PratheepaJ.github.io/project/sap-bcdf/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/sap-bcdf/","section":"project","summary":"Deriving the formula for the variable in saddlepoint approximation for bivariate cumulative distribution function.","tags":[],"title":"Saddlepoint Approximation for Bivariate Cumulative Distribution Function","type":"project"},{"authors":[],"categories":[],"content":"  The KM estimator is a commonly used nonparametric estimator of a survival function, but the KM estimator only defines the approximate probability of observed failure times and may not define a proper density function if the largest observation is right-censored.\nApplication We can apply this method for several event-time data from the clinical research to estimate a smooth survival curve.\n Method We define the empirical moment generating function (MGF) of the tail-completed density function based on the KM estimator, then, using the saddlepoint method, accurately approximate a smooth survival function. Before using the saddlepoint method for this purpose, however, we establish the convergence results of the modified version of the empirical MGF based on the KM estimator using the M-estimation and multivariate delta method.\n Software  R package ESPA. Tutorial.   Paper  Available in the Canadian Journal of Statistics:.\n PhD dissertation Chapter III.\n   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630890591,"objectID":"1ec6f5ef83930182e67572991a62671a","permalink":"https://PratheepaJ.github.io/project/espa/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/espa/","section":"project","summary":"Deriving a class of statistical methods to estimate a smooth survival curve sought to extend the empirical saddlepoint method based on the Kaplan-Meier (KM) estimator.","tags":[],"title":"Empirical Saddlepoint Approximations (ESPA) for Smoothing Survival Functions Under Right Censoring","type":"project"},{"authors":[],"categories":[],"content":"  Description Course link.\n Syllabus Course overview An introduction to data science theory is provided with some focus on analytics. Topics covered include an introduction to R and other appropriate computational platforms, data types, data manipulation, data frames, data visualization, data reporting, statistical/machine learning, classification, clustering, cross-validation, classification and regression trees, gradient boosting, ridge regression, LASSO, and generalized additive models. Familiarity with some computer package, e.g., SAS, Python, or MatLab, is required. This course includes a scientific communication component.\n Expected outcomes Upon completion of this course, the student will be able to:\n use visualization tools to explore the data using R perform analysis using unsupervised and supervised learning methods analyze a real data set of moderate size using R and interpret the output write reusable data analysis reports using R, RStudio, and RMarkdown    Course Information  Time:  C01: WF 3:30 PM - 4:20 PM L01: Tu 1:30 PM - 2:20 PM or L02: M 12:30 PM - 1:30 PM  Location: Virtual classroom discussion in Zoom (C01) and Virtual tutorial discussion in Zoom (L01 or L02) Sessional dates: January 11, 2021 - April 14, 2021   Prerequisites One of ECON 3EE3 or PNB 3XE3 or SFWRTECH 4DA3  or STATS 3A03.\n Textbook  Suggested textbooks:  ISLR: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani (Springer, 1st ed., 2013). - available at campus store. RDS: R for Data Science by Garrett Grolemund and Hadley Wickham. - available online. RMC: R Markdown Cookbook by Yihui Xie, Christophe Dervieux, Emily Riederer. - available online.    Software This course uses R and RStudio, which are both free. We recommend to set-up the computing environment earlier. We will also use the first-week lab session to ensure everyone is up and running with the computing environment.\n Install the following software (follow the interactive tutorial to install R and R Studio: click here):  R (required): https://www.r-project.org/. RStudio is highly recommended for syntax highlighting, package management, document generation, and more: https://www.rstudio.com/.  The newest version of RStudio is highly recommended.  Latex, which will enable you to create PDFs directly from the RMarkdown in RStudio.  Install TinyTex package: install.packages(\"tinytex\", repos = \"https://cloud.r-project.org/\"). After installing TinyTex, close RStudio. Reopen RStudio. Run the following: tinytex::install_tinytex().     Evaluation The homework assignments and bonus points will determine the final letter grade for this course:\n Six homework assignments will be assigned. The best five assignments will count towards your overall grade. Each of your five best assignments will be worth 20% of the final grade.  The final percentage to letter grade conversion will follow McMaster’s Grading Scale.\n  Lecture notes Course Schedule     Date Week Topic Readings Notes    01/11/2021 or 01/12/2021 Week 1 (Lab 1) Set up R, R Studio, RMarkdown example 1) Interactive tutorial to install R and R Studio 2) RMarkdown for Scientists Chapter 1-5   01/13/2021 Week 1 (Lecture 1) Course introduction 1) RDS Chapter 1-2 2) Outline 3) RMarkdown for Scientists Chapters 6-13 4) RDS Chapter 4   01/15/2021 Week 1 (Lecture 2) Data visualization I 1) RDS Chapter 3 2) RDS Chapter 7.1-7.2 3) Modern Statistics for Modern Biology Chapter 3   01/18/2021 or 01/19/2021 Week 2 (Lab 2) Week 1 computing in R 1) Homework assignment template and submission, 2) R tips - RDS Chapter 4, 3) RStudio diagnostics - RDS Chapter 6, 4) data visualization - RDS Chapter 7.1-7.2   01/20/2021 Week 2 (Lecture 3) Data visualization II 1) RDS Chapter 5, 2) RDS Chapter 7.3-7.8 Homework 1 posted  01/22/2021 Week 2 (Lecture 4) Data visualization III 1) RDS Chapter 7.3-7.8, 2) Word clouds - Text Mining With R Case study: comparing Twitter archives, 3) Network - Modern Statistics for Modern Biology Chapter 10, 4) Time series plots - https://www.r-graph-gallery.com/279-plotting-time-series-with-ggplot2.html   01/25/2021 or 01/26/2021 Week 3 (Lab 3) Week 2 computing in R 1) RDS Chapter 8 (create an RProject for STATS3DS3), 2) R commands for Lecture 3, 3) R commands for Lecture 4, 4) Word clouds - Text Mining With R Case study: comparing Twitter archives, 5) Network - Modern Statistics for Modern Biology Chapter 10, 6) Time series plots - https://www.r-graph-gallery.com/279-plotting-time-series-with-ggplot2.html   01/27/2021 Week 3 (Lecture 5) Interactive visualization Watch the video   01/29/2021 Week 3 (Lecture 6) Classification ISLR Pages 39 - 42 (K-Nearest Neighbors) Homework 1 Due  02/01/2021 or 02/02/2021 Week 4 (Lab 4) Week 3 computing in R 1) RMarkdown - RDS Chapter 26-27.4.2, 2) Shiny (Lecture 5), 3) KNN Classifier (Lecture 6) Homework 2 posted  02/03/2021 Week 4 (Lecture 7) Classification tree ISLR Chapter 8.1, 8.1.2, 8.1.4   02/05/2021 Week 4 (Lecture 8) Regression tree ISLR Chapter 8.1.1, 8.1.4   02/08/2021 or 02/09/2021 Week 5 (Lab 5) Week 4 computing in R 1) Text mining (word cloud) - Lab 3, 2) Classification trees - Breast Cancer Wisconsin (Diagnostic) Data Set from UCI Machine Learning Repository, 3) Strings in R *RDS** Chapter 14: Strings   02/10/2021 Week 5 (Lecture 9) Cross-validation ISLR Chapter 5.1   02/12/2021 Week 5 (Lecture 10) Bagging ISLR Chapter 8.2.1 Homework 3 posted, Homework 2 Due  02/15/2021 or 02/16/2021 Week 6 (No lab) Midterm recess    02/17/2021 Week 6 (Lecture 11) Midterm recess    02/19/2021 Week 6 (Lecture 12) Midterm recess    02/22/2021 or 02/23/2021 Week 7 (Lab 6) Week 5 computing in R 1) ISLR Lab 8.3.2 (regression tree), 2) ISLR Lab 8.3.3 (bagging)   02/24/2021 Week 7 (Lecture 13) Random forest and boosting 1) ISLR Chapter 8.2.2 and 8.2.3   02/26/2021 Week 7 (Lecture 14) Neural network The Elements of Statistical Learning Chapter 11.1-11.4 Homework 4 posted, Homework 3 Due  03/01/2021 or 03/02/2021 Week 8 (Lab 7) Week 7 computing in R 1) ISLR Lab 8.3.3 and 8.3.4 (RF and boosting) 2) classification using NN   03/03/2021 Week 8 (Lecture 15) Clustering I 1) ISLR Chapter 10.3.1   03/05/2021 Week 8 (Lecture 16) Clustering II 2) ISLR Chapter 10.3.1   03/08/2021 or 03/09/2021 Week 9 (Lab 8) Week 8 computing in R    03/10/2021 Week 9 (Lecture 17) PCA ISLR Chapter 10.2   03/12/2021 Week 9 (Lecture 18) Discriminant analysis I ISLR Chapter 4.4.1 and 4.4.2 Homework 5 posted, Homework 4 Due  03/15/2021 or 03/16/2021 Week 10 (Lab 9) Week 9 computing in R    03/17/2021 Week 10 (Lecture 19) Discriminant analysis II ISLR Chapter 4.4.3 and 4.4.4   03/19/2021 Week 10 (Lecture 20) Subset selection ISLR Chapter 6.1   03/22/2021 or 03/23/2021 Week 11 (Lab 10) Week 10 computing in R    03/24/2021 Week 11 (Lecture 21) Penalized regression I 1) ISLR Chapter 2.2, ISLR Chapter 6.2.1   03/26/2021 Week 11 (Lecture 22) Penalized regression II ISLR Chapter 6.2.2 and 6.2.3 Homework 6 posted, Homework 5 Due  03/29/2021 or 03/30/2021 Week 12 (Lab 11) Week 11 computing in R    03/31/2021 Week 12 (Lecture 23) Logistic regression I ISLR Chapter 4.3.1   04/02/2021    Good Friday: No classes or examinations  04/05/2021 or 04/06/2021 Week 13 (Lab 12) Week 12 computing in R    04/07/2021 Week 13 (Lecture 24) Logistic regression II ISLR Chapter 4.3.2 and 4.3.3   04/09/2021 Week 13 (Lecture 25) Sensitivity and specificity  Homework 6 Due  04/12/2021 or 04/13/2021 Week 14 (Lab 13) Week 13 computing in R    04/14/2021 Week 14 (Lecture 26) Wrap-up       Important dates     Date Day Description    January 11, 2021 Monday Classes begin  January 19, 2021 Thuesday Last day for enrollment and course changes (drop/add)  February 15 to February 19, 2021 Monday- Friday Mid-term recess  March 19, 2021 Friday Last day for withdrawing from courses without failure by default  April 2, 2021 Friday Good Friday: No classes or examinations  April 8 to April 14, 2021 Thursday - Wednesday Test and Examination Restriction  April 14, 2021 Wednesday Classes End  April 15 to April 30, 2021 Thursday - Friday Final Examinations     R Markdown files Available upon request.\n  ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630900123,"objectID":"a770e2814a5a3064e736df1a43365d3c","permalink":"https://PratheepaJ.github.io/teaching/stats3ds3/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/teaching/stats3ds3/","section":"teaching","summary":"Intoduction to Data Science Theory.","tags":[],"title":"STATS 3DS3 (Winter 2021, McMaster)","type":"teaching"},{"authors":[],"categories":[],"content":"  The AR models are typically used to model the time series data. Several possible procedures exist for estimating model parameters. We refer to some of them as Yule-Walker (YW) estimators (Yule, 1927), least squares estimators, Burg estimators (Burg, 1968), and maximum likelihood estimators. Although the YW estimators produce bias in the estimation, this is a commonly used estimation method in practice.\nApplication Once the AR model is fit to the data, it is common to check the significance of model parameters. We then identify the order of the AR model.\n Method We derive the bivariate saddlepoint density approximation for the YW estimators of AR(2) model parameters. First, we write the sample autocorrelation as the ratio of quadratic forms. Then, we substitute this ratio in the YW equations and derive a system of quadratic estimating equations (QEE). Next, we show that the YW estimators of AR(2) model parameters are roots of QEE. We also show that the Jacobian of the transformation of the QEE coordinate space to the parameter coordinate space is positive semi-definite. Finally, we derive the bivariate saddlepoint density approximation using that of QEE.\n Software  PhD dissertation Chapter II supplement.   Paper  PhD dissertation Chapter II.   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630892209,"objectID":"0bbde617ef7e1061d52f7a99b1bd8bcd","permalink":"https://PratheepaJ.github.io/project/msap/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/msap/","section":"project","summary":"Estimating the joint density of Yule-Walker (YW) estimators by inverting the joint saddlepoint density of the YW estimating equations in an AR(2) model.","tags":[],"title":"Multivariate Saddlepoint Density Approximation (MSAP)","type":"project"},{"authors":[],"categories":[],"content":"  Description Course link.\n Syllabus Course Overview Statistical tools for modern data analysis. Topics include regression and prediction, elements of the analysis of variance, bootstrap, and cross-validation. Emphasis is on conceptual rather than theoretical understanding. Student assignments require use of the software package R.\n Expected outcomes By the end of the course, students should be able to:\n Enter tabular data using R. Plot data using R, to help in exploratory data analysis. Formulate regression models for the data, while understanding some of the limitations and assumptions implicit in using these models. Fit models using R and interpret the output. Test for associations in a given model. Use diagnostic plots and tests to assess the adequacy of a particular model. Find confidence intervals for the effects of different explanatory variables in the model. Use some basic model selection procedures, as found in R, to find a best model in a class of models. Fit simple ANOVA models in R, treating them as special cases of multiple regression models. Fit simple logistic and Poisson regression models.   Course Information  Term: Autumn 2019 Units: 3 Time: Mon, Wed, Fri 1:30 PM - 2:20 PM Location: Gates B3 LEC: 09/23/2019 - 12/06/2019 (10 Weeks - 30 hours)   Prerequisites An introductory statistics course, such as - STATS 60 or STATS 110 or STATS 141.\n Textbook  Required:  (CH) Regression Analysis by Example.  Authors: Samprit Chatterjee, Ali S. Hadi Edition: \\(5^{th}\\) Edition Print ISBN:978-0-470-90584-05     Software  In this course, we will use R for computing and R Markdown for producing lecture slides, solutions for homework assignments. R Markdown is highly recommended to write the solutions for homework assignments. Install the following software:  R (required): https://www.r-project.org/. R Studio is highly recommended for syntax highlighting, package management, document generation, and more: https://www.rstudio.com/.  The newest version of R Studio is highly recommended.  Latex, which will enable you to create PDFs directly from the R Markdown in RStudio.  Install Tinytex  install.packages(‘tinytex’) tinytex::install_tinytex()      Evaluation The final letter grade for this course will be determined by each method of assessment weighted as follows:\n 7 weekly homework assignments (55%) Midterm examination (15%, Wednesday, 10/23/2019) Final examination (30%, according to Stanford calendar: Wednesday, 12/11/2019 @ 3:30 PM, location TBD)   Policies  Class Participation  Bonus points 5%. Pop quizzes will be given in class (SCPD students can complete in 24 hours). Scan your hand-written solutions as a PDF file/write down your answer in R markdown and render your answer to PDF and upload your answers to gradescope. In-class participation and Piazza discussion are encouraged.  Find our class page at: https://piazza.com/stanford/fall2019/stats191/home This term we will be using Piazza for class discussion. The system is highly catered to getting you help fast and efficiently from classmates, the TA, and myself. Rather than emailing questions to the teaching staff, I encourage you to post your questions on Piazza. If you have any problems or feedback for the developers, email team@piazza.com.  When homework involves simulations and data analysis, you will use R statistical computing software. Please post your R or R Markdown questions to Piazza. Instructor or TA or other students in your class can answer your questions. When asking questions about code, be specific (copy and paste the exact error, relevant code, and describe what you are attempting to do). We will not answer questions that are too similar to the problem sets or that would be better answered in office hours with a whiteboard. Needless to say, you should conduct yourself in a courteous and respectful manner on Canvas Discussion.  Weekly homework assignments  Homework assignment will be assigned every Friday on Canvas Assignments. Homework assignment will be due every Friday.  Prepare your completed homework assignment in PDF format and submit a copy to gradescope. Write the solution for each question on a new page (use \\newpage).  Use R markdown in R Studio and render it to PDF  See the following link for further outline of using R markdown for reporting.  Each question in the homework assignment will be graded as follows: \\(scale \\in \\left\\lbrace 0,1,2\\right\\rbrace\\)  2: submitted on time and more or less correct answer 1: submitted on time and partially correct answer 0: submitted with a completely incorrect answer or late submission (any day after the due date for more than one homework assignment).  Each student can hand in only one homework late (within three days after the deadline). After attempting homework problems on an individual basis, students may discuss a homework assignment with their classmates. However, students must write up their own solutions individually and explicitly indicate from whom (if anyone) or resources students received help at the top of their homework solutions.  Midterm examination  In-class examination: Wednesday, October 23, 2019 @ 1:30PM - 2.20 PM, Gates B3. Students are not allowed to take midterm examinations other than the scheduled date and time (except for the event of extraordinary circumstance that is determined solely by me.)  Final examination  In-class examination. Following the Stanford calendar: Wednesday, December 11, 2019 @ 3:30PM-6:30 PM, location TBD. Students are not allowed to take final examinations earlier than the scheduled date and time (except for the event of extraordinary circumstance that is determined solely by me.). Students are not allowed to take this course with another conflicting final examination schedule.  Accessible Education  Students with Documented Disabilities: Students who may need an academic accommodation based on the impact of a disability must initiate the request with the Office of Accessible Education (OAE). Professional staff will evaluate the request with required documentation, recommend reasonable accommodations, and prepare an Accommodation Letter for faculty. Unless the student has a temporary disability, Accommodation letters are issued for the entire academic year. Students should contact the OAE as soon as possible since timely notice is needed to coordinate accommodations. The OAE is located at 563 Salvatierra Walk (phone: 723-1066, URL:https://oae.stanford.edu/.) Provide me an accommodation letter on or before 09/30/2019.  Honor Code  Students are bound by the Stanford Honor Code. Violation of the honor code will result in a failing grade among other penalties.  Stanford Center for Professional Development (SCPD)  Stats 191 is listed as one of the SCPD courses. Lecture recordings are being made and might be shared with others at Stanford beyond those currently enrolled in the class. SCPD policies on student privacy: Video cameras located in the back of the room will capture the instructor presentations in this course. For your convenience, you can access these recordings by logging into the course Canvas site. These recordings might be reused in other Stanford courses, viewed by other Stanford students, faculty, or staff, or used for other education and research purposes. Note that while the cameras are positioned with the intention of recording only the instructor, occasionally a part of your image or voice might be incidentally captured. If you have questions, please contact a member of the teaching team.     Lecture Notes Course Schedule     Date Week Topic Reading Notes    09/23/2019 Week 1 Lecture 1 Course introduction and review Syllabus, Lecture notes   09/25/2019 Week 1 Lecture 2 Review CH: Chapter 1   09/27/2019 Week 1 Lecture 3 Some tips on R Lecture notes Homework 1 posted  09/30/2019 Week 2 Lecture 4 Simple linear regression 1 (introduction, correlation, model, estimation) CH: Chapter 2.1-2.4 –  10/02/2019 Week 2 Lecture 5 Simple linear regression 2 (inference and prediction) CH: Chapter 2.5-2.8 –  10/04/2019 Week 2 Lecture 6 Diagnostics for simple linear regression CH: Chapter 2.9 Homework 2 posted, Homework 1 Due  10/07/2019 Week 3 Lecture 7 Multiple linear regression 1 (introduction, model, estimation, geometry of least squares) CH: Chapter 3.1-3.5 –  10/09/2019 Week 3 Lecture 8 Multiple linear regression 2 (interpretation, matrix formulation, estimation, inference) CH: Chapter 3.6-3.9 –  10/11/2019 Week 3 Lecture 9, Lecture 9 Multiple linear regression 3 (prediction, contrasts, testing) CH: Chapter 3.10-3.11 Homework 3 posted, Homework 2 Due  10/14/2019 Week 4 Lecture 10 Diagnostics in multiple linear regression (types of residuals, influence) CH: Chapter 4 –  10/16/2019 Week 4 Lecture 11 Diagnostics in multiple linear regression (outlier detection, residual plots) CH: Chapter 4 –  10/18/2019 Week 4 Lecture 12 Interactions and qualitative variables (interactions) CH: Chapter 5 Homework 4 posted, Homework 3 Due  10/21/2019 Week 5 Lecture 13 Interactions and qualitative variables (visualization, ANOVA) CH: Chapter 5 –  10/23/2019 Week 5  – – Midterm Examinations   10/25/2019 Week 5 Lecture 15 ANOVA models (one-way ANOVA, testing, contrasts) CH: Chapter 5 –  10/28/2019 Week 6 Lecture 16 ANOVA models (two-way ANOVA, testing, contrasts, mixed effects model) CH: Chapter 5 –  10/30/2019 Week 6 Lecture 17 Transformations and Weighted Least Squares CH: Chapter 6,7 –  11/01/2019 Week 6 Lecture 18 Correlated errors CH: Chapter 8,9 Homework 5 posted, Homework 4 Due  11/04/2019 Week 7 [Lecture 19] Correlated errors CH: Chapter 8,9 –  11/06/2019 Week 7 Lecture 20 Bootstrapping regression Lecture notes will be provided –  11/08/2019 Week 7 Lecture 21 Selection CH: Chapter 11 Homework 6 posted, Homework 5 Due  11/11/2019 Week 8 [Lecture 22] Selection CH: Chapter 11 –  11/13/2019 Week 8 [Lecture 23] Selection CH: Chapter 11 –  11/15/2019 Week 8 Lecture 24 Penalized regression CH: Chapter 10 Homework 7 posted, Homework 6 Due  11/18/2019 Week 9 [Lecture 25] Penalized regression CH: Chapter 10 –  11/20/2019 Week 9 [Lecture 26] Penalized regression CH: Chapter 10 –  11/22/2019 Week 9 Lecture 27 Logistic regression CH: Chapter 12 Homework 7 Due  11/25/2019 – – – Thanksgiving Recess (no classes)  11/27/2019 – – – Thanksgiving Recess (no classes)  11/29/2019 – – – Thanksgiving Recess (no classes)  12/02/2019 Week 10 [Lecture 28] Logistic regression CH: Chapter 12 –  12/04/2019 Week 10 [Lecture 29] Poisson regression CH: Chapter 13.3 –  12/06/2019 Week 10 Lecture 30 Final Review Review will be posted –  12/11/2019  – – End-Quarter examinations      Important Dates     Date Day Description    10/11/2019 Friday, 5:00 p.m. Last day to add or drop a class  10/23/2019 Wednesday, 1:30-2:20 p.m. Midterm examination  11/04/2019 Monday, 5:00 p.m. Term withdrawal deadline with a partial refund  11/25/2019- 11/29/2019 Monday - Friday Thanksgiving Recess (no classes)  12/02/2019 - 12/08/2019 Monday - Sunday End-Quarter Period  12/06/2019 Friday Last day of classes  12/11/2019 Wednesday Final Examinations @ 3:30 p.m. - 6.30 p.m.  12/17/2019 Tuesday, 11.59 p.m. Grades due     R Markdown files R Markdown files to create the lecture slides are available here.\n  ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630900007,"objectID":"77f6f41f31e8b4aebd0300fb0541f425","permalink":"https://PratheepaJ.github.io/teaching/stats191/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/teaching/stats191/","section":"teaching","summary":"Introduction to Applied Statistics.","tags":[],"title":"STATS 191 (Autumn 2019, Stanford)","type":"teaching"},{"authors":[],"categories":[],"content":"  We consider a class of statistical methods called the saddlepoint-based bootstrap (SPBB) method to make inferences about the spatial dependence parameter in the spatial regression model.\nApplication For example, in spatial econometrics, we can use the SPBB method to infer the significance of the spatial dependence parameter. We can use either the spatial autoregressive model, conditional autoregressive model, or spatial moving average models to fit the spatial lattice data.\n Method We use the SPBB method to construct confidence intervals for a parameter whose estimator is a unique root of a quadratic estimating equation. In the SPBB method, we use the monotonicity of the quadratic estimating equation in parameter to relate the distribution of an estimator to the distribution of the respective quadratic estimating equation. Using the saddlepoint methods, it is then possible to accurately approximate the distribution of the estimator. Then confidence interval can be produced by pivoting the distribution of the estimator.\n Software  R package SPBBspatial. Tutorial.   Paper  Available in Spatial statistics.\n Master thesis.\n   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630888277,"objectID":"a28f2e135c3f5bad30c2f2e813d02c74","permalink":"https://PratheepaJ.github.io/project/spbb/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/spbb/","section":"project","summary":"Indirect inference about the spatial dependence parameter in the spatial regression model through estimating equation.","tags":[],"title":"Saddlepoint-Based Bootstrap Method (SPBB)","type":"project"},{"authors":[],"categories":[],"content":"  Description Course link.\n Syllabus Course Overview This course covers nonparametric analogs of the one- and two-sample t-tests and analysis of variance; the sign test, median test, Wilcoxon’s tests, and the Kruskal-Wallis and Friedman tests, tests of independence; nonparametric regression and nonparametric density estimation; modern nonparametric techniques; nonparametric confidence interval estimates.\n Expected outcomes By the end of the course, the student should be able to\n understand the assumptions underlying the nonparametric methods apply nonparametric methods to modern data analysis problems get hands-on experience in implementing methods and using existing R packages.   Course Information  Term: Spring 2019 Units: 3 Time: Mon, Wed, Fri 1:30 PM - 2:20 PM Location: LEC: 04/01/2019 - 06/05/2019 (10 Weeks - 30 hours)   Prerequisites  STATS 60 or STATS 110 or STATS 160; Students should familiar with summary statistics, hypothesis testing, point estimation, interval estimation (confidence intervals), basics of statistical inference, and R.   Texts  Required:  (HWC) Nonparametric Statistical Methods.  Authors: Myles Hollander, Douglas A. Wolfe, Eric Chicken Edition: \\(3^{rd}\\) Edition Print ISBN:9780470387375 Online ISBN:9781119196037   Recommended:  (DH): Davison and Hinkley (1997). Boostrap Method and Their Application.  (ET): Efron and Tibshirani (1994). An Introduction to the Bootstrap. (KM): Kloke and McKean (2015). Nonparametric Statistical Methods Using R. (L): Lehmann (2006). Nonparametrics: Statistical Methods Based on Ranks. (RHG): Ramsay, Hooker, Graves (2009). Functional Data Analysis with R and MATLAB. (W): Wasserman (2006). All of Nonparametric Statistics.    Other sources  Recommended Readings: a reading list will be posted on Canvas.  Re:BHLLSW2009: Buja, Cook, Hofmann, Lawrence, Lee, Swayne, and Wickham (2009). Statistical Inference for Exploratory Data Analysis and Model Diagnostics. Re:D1983: Diaconis (1983). Theories of Data Analysis: From Magical Thinking Through Classical Statistics. Re:DH1994: Diaconis and Holmes (1994). Gray Codes for Randomization Procedures. Re:DH1995: Diaconis and Holmes (1995). Discrete Probability and Algorithms: Three Examples of Monte-Carlo Markov Chains: At the Interface Between Statistical Computing, Computer Science, and Statistical Mechanics, pg. 43-56. Re:JWH2014: Josse, Wager, and Husson (2014). Confidence Areas for Fixed-Effects PCA.  Useful links  Li:H1997: Holmes (1997). Lecture Notes on Computer Intensive Methods in Statistics. Li:H2004: Holmes (2004). Lecture Notes on Complete Enumeration. Li:C2016: Seiler (2016). Lecture Notes on Nonparametric Statistics. Li:W2016: Wasserman (2016). Lecture Notes on Nonparametric Bayesian Methods.    Software  In this course, we will use R for computing and R Markdown for producing lecture slides, solutions for homework assignments. R Markdown/Latex is highly recommended to write the midterm project proposal report and final project report. Install the following software:  R (required): https://www.r-project.org/. R Studio is highly recommended for syntax highlighting, package management, document generation, and more: https://www.rstudio.com/.  The newest version of R Studio is highly recommended (v1.1.463).  Latex, which will enable you to create PDFs directly from the R Markdown in RStudio.  Latex, which will enable you to create PDFs directly from the R Markdown in RStudio. Install Tinytex  install.packages(‘tinytex’) tinytex::install_tinytex()      Grading The final letter grade for this course will be determined by each method of assessment weighted as follows:\n Class participation (5%) Weekly homework assignments (50%) Midterm project proposal (10%, due on 05/03/2019) Final project (35%, due on 06/05/2019)    Lecture Notes Course Schedule     Date Week Topic Reading Notes    04/01/2019 Week 1 Lecture 0 Overview of current research in nonparametric and adequate initiation to R and R Markdown ASA Nonparametric statistics section news gives an overview of some current research topics; install R; install RStudio; TryR, R Markdown webinar, R Markdown provide adequate initiation to R and R Markdown.   04/03/2019 Week 1 Lecture 1 Logistics and Preliminaries Syllabus, HWC: Chapter 1   04/05/2019 Week 1 Lecture 2 The One-sample problem I (testing procedure) HWC: Chapter 3.4-3.6, 3.8, 3.1-3.3, 3.7 Homework 1 posted  04/08/2019 Week 2 Lecture 3 The One-sample problem II (estimator associated with the statistic, confidence interval, example) HWC: Chapter 3.4-3.6, 3.8, 3.1-3.3, 3.7   04/10/2019 Week 2 Lecture 4 Statistical functionals and Influence functions Notes will be posted on W: Chapter 2, ET: Chapter 4, 5, 21.3   04/12/2019 Week 2 Lecture 5 Jackknife and Bootstrap I HWC: Chapter 8.4 and notes will be posted based on W: Chapter 3, DH, ET: Chapter 6, 11 Homework 2 Posted, Homework 1 Due  04/15/2019 Week 3 Lecture 6 Bootstrap II Notes will be posted based on ET: Chapter 23, Re:DH1994, Re:DH1995   04/17/2019 Week 3 Lecture 7 Discrete data problems I HWC: Chapter 2   04/19/2019 Week 3 Lecture 8 Discrete data problems II HWC: Chapter 10 Homework 3 Posted, Homework 2 Due  04/22/2019 Week 4 Lecture 9 Two-sample problem I HWC: Chapter 4   04/24/2019 Week 4 Lecture 10 Two-sample problem II HWC: Chapter 5   04/26/2019 Week 4 Lecture 11 Permutation Test I  Homework 4 Posted, Homework 3 Due  04/29/2019 Week 5 Lecture 12 Permutation Test II    05/01/2019 Week 5 Lecture 13 Ranked-based linear regression HWC: Chapter 9   05/03/2019 Week 5 Lecture 14 Smoothing I W: Chapter 4 Midterm project proposal due  05/06/2019 Week 6 Lecture 15 Nonparametric regression I HWC: Chapter 9.7, 14, W: Chapter 5   05/08/2019 Week 6 Lecture 16 Nonparametric regression II HWC: Chapter 9.7, 14, W: Chapter 5   05/10/2019 Week 6 Lecture 17 Wavelets HWC: Chapter 13, W: Chapter 9 Homework 5 Posted, Homework 4 Due  05/13/2019 Week 7 Lecture 18 ANOVA I HWC: Chapter 6, 7   05/15/2019 Week 7 Lecture 19 ANOVA II , multiple comparison HWC: Chapter 6, 7   05/17/2019 Week 7 Survival analysis I HWC: Chapter 10 Homework 6 Posted, Homework 5 Due  05/20/2019 Week 8 Survival analysis II HWC: Chapter 10   05/22/2019 Week 8 Ranked set sampling HWC: Chapter 15   05/24/2019 Week 8 Bayesian nonparametric I HWC: Chapter 16, Li:W2016 Homework 7 Posted, Homework 6 Due  05/27/2019 Week 9 (Holiday, no classes)  Memorial Day  05/29/2019 Week 9 Bayesian nonparametric II HWC: Chapter 16, Li:W2016   05/31/2019 Week 9 Lecture 25 Inference for data visualization Re:BHLLSW2009, Re:D1983, Re:JWH2014 Homework 7 Due (no late submission allowed, End-Quarter Period starts)  06/03/2019 Week 10 Lecture 26 Bootstrap III ET: Chapter 12, 14   06/05/2019 Week 10 Lecture 27 Wrap-up  Final project due     R Markdown files R Markdown files to create the lecture slides are available here.\n  ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630899855,"objectID":"3e74ea22faaffd7ce48dccfb01342319","permalink":"https://PratheepaJ.github.io/teaching/stats205/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/teaching/stats205/","section":"teaching","summary":"Introduction to Nonparametric Statistics.","tags":[],"title":"STATS 205 (Spring 2019, Stanford)","type":"teaching"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://PratheepaJ.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fba6c149775da15c6a5b2adae893dd1c","permalink":"https://PratheepaJ.github.io/joinus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/joinus/","section":"","summary":"Join Jeganathan research group at McMaster University","tags":null,"title":"Join Us","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6e7e6c64a47fc68754e543944bd2c2ab","permalink":"https://PratheepaJ.github.io/researchgroup/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/researchgroup/","section":"","summary":"People at Jeganathan's research group","tags":null,"title":"Research group","type":"widget_page"}]
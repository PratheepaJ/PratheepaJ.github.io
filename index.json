[{"authors":[],"categories":[],"content":"   Methods  Integrating spatial targeted-proteomics data Deriving features to represent spatial proximities of two spatial point processes Integrative approaches for spatial transcriptomics data (visual cortex)  Applciation  Predict the survival of breast cancer patients based on tumor-immune environment    Methods Integrating spatial targeted-proteomics data  Deriving features to represent spatial proximities of two spatial point processes  Integrative approaches for spatial transcriptomics data (visual cortex)   Applciation Predict the survival of breast cancer patients based on tumor-immune environment   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630899299,"objectID":"f7608f1b328992390bea1752f73cf175","permalink":"https://PratheepaJ.github.io/project/spatial-multiomics/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/spatial-multiomics/","section":"project","summary":"Methods for analyzing cellular, molecular, and spatial data.","tags":[],"title":"Spatial multi-omics","type":"project"},{"authors":[],"categories":[],"content":"   Methods  Container Transformation Metatranscriptomics and marker-gene integration  Applications  Vaginal microbiome data Integrative human microbiome project    Methods Container Microbiome multi-omics includes maker-gene sequencing, metagenomics, metatranscriptomics, metabolomics, and cytokines. A container build from SummarizeExperiment class in Bioconductor can facilitate microbiome multi-omics integrative approaches.\n Transformation Transformation and imputation methods are needed to explore microbiome multi-omics.\n Metatranscriptomics and marker-gene integration   Applications Vaginal microbiome data  Integrative human microbiome project   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630899138,"objectID":"bdc29b4547574d181d3ad011c12d11d6","permalink":"https://PratheepaJ.github.io/project/micro-multiomics/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/micro-multiomics/","section":"project","summary":"Methods for analyzing microbiome multi-omics.","tags":[],"title":"Microbiome multi-omics","type":"project"},{"authors":[],"categories":[],"content":"   Methods  Differential topic analysis DNA contamination removal in molecular microbial studies Inference on longitudinal microbiome data  Applications  diffTop BARBI BootLong    Methods Differential topic analysis In microbiome research, an important goal is often to find taxonomic differences across environments or groups. We introduce differential topic analysis that facilitates inferences on latent microbial communities.\n Software  R package is available in Github: diffTop Tutorial is available at diffTop  Papers and Preprint  A Statistical Perspective on the Challenges in Molecular Microbial Biology, Journal of Agricultural, Biological and Environmental Statistics.  Talks  BioC 2021, August 4, 2021. Slides. R-Ladies Dallas, July 12, 2021. Slides. International Conference on Environmental and Medical Statistics, January 9, 2020.    DNA contamination removal in molecular microbial studies Molecular technologies can quantify bacteria in low biomass samples, such as blood. However, DNA contamination from external sources misidentifies the taxon’s provenance. We developed a Bayesian reference analysis to infer DNA contamination.\n Software  R package is available in Github: BARBI. Tutorial is available at BARBI.  Papers and Preprint  Method paper (To be submitted).  Talks  Statistics Seminar, Department of Statistics, Stanford University - June 2, 2020. 21st Meeting of New Researchers in Statistics and Probability - July 24-27, 2019. 3rd Workshop on Statistical and Algorithmic Challenges in Microbiome Data Analysis - April 2, 2019.    Inference on longitudinal microbiome data Longitudinal designs help experimenters overcome some of the difficulties caused by the temporal and subject-to-subject variability of the microbiome. They also allow subjects to be used as their own controls.\nThe proposed resampling method combined moving block bootstrap (MBB) method, empirical subsampling method, mixture model, generalized linear model, generalized estimating equation, median-ratio method, and shrinkage estimation to enabling inference on microbiome longitudinal data. With the optimal block size computed using subsampling, the MBB method accounts for within-subject dependency by using overlapping blocks of repeated observations within each subject to draw valid inferences based on approximately pivotal statistic.\n Software  R package is available in Github: bootLong Tutorial is available at bootLong  Papers and Preprint  The Block Bootstrap Method for Longitudinal Microbiome Data, Stat arXiv.  Talks  Biomedical Computation at Stanford 2018, April 19, 2018.     Applications diffTop  In progress…   BARBI  Application to identify translocation of bacteria (To be submitted) Combined use of metagenomic sequencing and host response profiling for the diagnosis of suspected sepsis. BioRxiv   BootLong  Identify deferentially abundant taxa in preterm and term labor (vaginal microbiome data).    ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630898684,"objectID":"5148c92fe1b810c5c039a99241371965","permalink":"https://PratheepaJ.github.io/project/micro/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/micro/","section":"project","summary":"Methods for analyzing marker-gene and shotgun metagenomics data.","tags":[],"title":"Molecular microbial data analysis","type":"project"},{"authors":[],"categories":[],"content":"   Application Method Software Paper   Wang (1990) devised an analytical approximation for the bivariate CDF for a rectangular set using the Lugannani and Rice (1980) formula and the standard bivariate normal distribution. We considered the theoretical study of the saddlepoint approximation for the bivariate distributions and provided necessary corrections and clarifications for the formula established by Wang (1990).\nThe numerical methods are used to compute the probability when the set is non-rectangular. There are many applications where inferences on a particular parameter \\(\\theta_{1}\\) in the presence of other \\(k-1\\) parameters are necessary. Obtaining a marginal probability distribution for \\(\\hat{\\theta}_{1}\\) is a straightforward matter of letting the arguments corresponding to the remaining parameters approach infinite values in the joint CDF of \\(k\\) estimators. In order to approximate the joint CDF of estimators, we consider a class of problems in which the estimators \\(\\left[\\hat{\\theta}_{1}, \\ldots, \\hat{\\theta}_{k}\\right]^{T}\\) may be determined as the roots of \\(k\\) distinct estimating equations.\nApplication We can construct a joint confidence region for multi-dimensional parameters.\n Method First, we derive estimating equations as a vector of quadratic forms in normal random variables. Then, we identify the moment-generating function of quadratic forms in a normal random variable. Next, we derive the necessary and sufficient conditions to approximate the CDF of estimators via estimating equations. Finally, we invert the CDF of estimators to construct a joint confidence region.\n Software  PhD dissertation Chapter I, section 1.2 supplement.   Paper  PhD dissertation Chapter I, section 1.2.   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630896491,"objectID":"b4ee45b03189250f0af95858a1918e13","permalink":"https://PratheepaJ.github.io/project/mspbb/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/mspbb/","section":"project","summary":"Deriving a class of statistical methods, bivariate SPBB which is an indirect method to construct a confidence region for the parameter(s) of interest.","tags":[],"title":"Multivariate Saddlepoint-Based Bootstrap Method (MSPBB)","type":"project"},{"authors":[],"categories":[],"content":"   Application Method Software Paper   We identify the expression for the variable that was not defined in Wang (1990) to approximate the bivariate distributions.\nApplication Construct confidence interval by inverting joint distribution of the estimators (MSPBB).\n Method Wang (1990) derived the saddlepoint approximation for bivariate distributions using the saddlepoint approximation for distribution (Lugannani \u0026amp; Rice, 1980) and standard bivariate normal distribution. We used complex analysis to derive the expression for the variable that was not defined in Wang (1990) to approximate the bivariate distributions.\n Software  PhD dissertation Chapter I, section 1.3 supplement.   Paper  PhD dissertation Chapter I, section 1.3.   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630895916,"objectID":"ea443e0abbab6521b5b12c3fa0681aa1","permalink":"https://PratheepaJ.github.io/project/sap-bcdf/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/sap-bcdf/","section":"project","summary":"Deriving the formula for the variable in saddlepoint approximation for bivariate cumulative distribution function.","tags":[],"title":"Saddlepoint Approximation for Bivariate Cumulative Distribution Function","type":"project"},{"authors":[],"categories":[],"content":"   Application Method Software Paper   The KM estimator is a commonly used nonparametric estimator of a survival function, but the KM estimator only defines the approximate probability of observed failure times and may not define a proper density function if the largest observation is right-censored.\nApplication We can apply this method for several event-time data from the clinical research to estimate a smooth survival curve.\n Method We define the empirical moment generating function (MGF) of the tail-completed density function based on the KM estimator, then, using the saddlepoint method, accurately approximate a smooth survival function. Before using the saddlepoint method for this purpose, however, we establish the convergence results of the modified version of the empirical MGF based on the KM estimator using the M-estimation and multivariate delta method.\n Software  R package ESPA. Tutorial.   Paper  Available in the Canadian Journal of Statistics:.\n PhD dissertation Chapter III.\n   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630890591,"objectID":"1ec6f5ef83930182e67572991a62671a","permalink":"https://PratheepaJ.github.io/project/espa/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/espa/","section":"project","summary":"Deriving a class of statistical methods to estimate a smooth survival curve sought to extend the empirical saddlepoint method based on the Kaplan-Meier (KM) estimator.","tags":[],"title":"Empirical Saddlepoint Approximations (ESPA) for Smoothing Survival Functions Under Right Censoring","type":"project"},{"authors":[],"categories":[],"content":"   Description Syllabus  Course overview Expected outcomes Course Information Prerequisites Textbook Software Evaluation  Lecture notes  Course Schedule R Markdown files    Description Course link.\n Syllabus Course overview An introduction to data science theory is provided with some focus on analytics. Topics covered include an introduction to R and other appropriate computational platforms, data types, data manipulation, data frames, data visualization, data reporting, statistical/machine learning, classification, clustering, cross-validation, classification and regression trees, gradient boosting, ridge regression, LASSO, and generalized additive models. Familiarity with some computer package, e.g., SAS, Python, or MatLab, is required. This course includes a scientific communication component.\n Expected outcomes Upon completion of this course, the student will be able to:\n use visualization tools to explore the data using R perform analysis using unsupervised and supervised learning methods analyze a real data set of moderate size using R and interpret the output write reusable data analysis reports using R, RStudio, and RMarkdown    Course Information 2 Lectures and 1 Lab.  Prerequisites One of ECON 3EE3 or PNB 3XE3 or SFWRTECH 4DA3  or STATS 3A03.\n Textbook  Suggested textbooks:  ISLR: An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani (Springer, 1st ed., 2013). - available at campus store. RDS: R for Data Science by Garrett Grolemund and Hadley Wickham. - available online. RMC: R Markdown Cookbook by Yihui Xie, Christophe Dervieux, Emily Riederer. - available online.    Software This course uses R and RStudio, which are both free. We recommend to set-up the computing environment earlier. We will also use the first-week lab session to ensure everyone is up and running with the computing environment.\n Install the following software (follow the interactive tutorial to install R and R Studio: click here):  R (required): https://www.r-project.org/. RStudio is highly recommended for syntax highlighting, package management, document generation, and more: https://www.rstudio.com/.  The newest version of RStudio is highly recommended.  Latex, which will enable you to create PDFs directly from the RMarkdown in RStudio.  Install TinyTex package: install.packages(\"tinytex\", repos = \"https://cloud.r-project.org/\"). After installing TinyTex, close RStudio. Reopen RStudio. Run the following: tinytex::install_tinytex().     Evaluation The homework assignments and bonus points will determine the final letter grade for this course:\n Six homework assignments will be assigned. The best five assignments will count towards your overall grade. Each of your five best assignments will be worth 20% of the final grade.  The final percentage to letter grade conversion will follow McMaster’s Grading Scale.\n  Lecture notes Course Schedule     Date Week Topic Readings Notes    01/11/2021 or 01/12/2021 Week 1 (Lab 1) Set up R, R Studio, RMarkdown example Interactive tutorial to install R and R Studio, RMarkdown for Scientists Chapters 1-5   01/13/2021 Week 1 (Lecture 1) Course introduction RDS: 1, 2, and 4, RMarkdown for Scientists Chapters 6-13   01/15/2021 Week 1 (Lecture 2) Data visualization I RDS: 3, 7.1-7.2, Modern Statistics for Modern Biology: Chapter 3   01/18/2021 or 01/19/2021 Week 2 (Lab 2) Week 1 computing in R Homework assignment template and submission, R tips - RDS: 4, RStudio diagnostics - RDS: 6, Data visualization - RDS : 7.1-7.2   01/20/2021 Week 2 (Lecture 3) Data visualization II RDS: 5, 7.3-7.8 Homework 1 posted  01/22/2021 Week 2 (Lecture 4) Data visualization III 1) RDS: 7.3-7.8, Word clouds - Text Mining With R Case study: comparing Twitter archives, Network - Modern Statistics for Modern Biology Chapter 10, Time series plots - https://www.r-graph-gallery.com/279-plotting-time-series-with-ggplot2.html   01/25/2021 or 01/26/2021 Week 3 (Lab 3) Week 2 computing in R RDS: Chapter 8 (create an RProject for STATS3DS3), R codes for Lecture 3, R codes for Lecture 4, Word clouds, Network, Time series plots   01/27/2021 Week 3 (Lecture 5) Interactive visualization and Shiny Watch the video   01/29/2021 Week 3 (Lecture 6) Classification ISLR: Pages 39 - 42 (K-Nearest Neighbors) Homework 1 Due  02/01/2021 or 02/02/2021 Week 4 (Lab 4) Week 3 computing in R RMarkdown - RDS : 26-27.4.2, Shiny (Lecture 5), KNN Classifier (Lecture 6) Homework 2 posted  02/03/2021 Week 4 (Lecture 7) Classification tree ISLR: 8.1, 8.1.2, 8.1.4   02/05/2021 Week 4 (Lecture 8) Regression tree ISLR: 8.1.1, 8.1.4   02/08/2021 or 02/09/2021 Week 5 (Lab 5) Week 4 computing in R Classification trees, Strings in R - RDS: 14   02/10/2021 Week 5 (Lecture 9) Cross-validation ISLR: 5.1   02/12/2021 Week 5 (Lecture 10) Bagging ISLR: 8.2.1 Homework 3 posted, Homework 2 Due  02/15/2021 or 02/16/2021 Week 6 Midterm recess    02/17/2021 Week 6 Midterm recess    02/19/2021 Week 6 Midterm recess    02/22/2021 or 02/23/2021 Week 7 (Lab 6) Week 5 computing in R ISLR: 8.3.2 (regression tree), ISLR: 8.3.3 (bagging)   02/24/2021 Week 7 (Lecture 11) Random forest and boosting ISLR: 8.2.2, 8.2.3   02/26/2021 Week 7 (Lecture 12) Neural network The Elements of Statistical Learning: 11.1-11.4 Homework 4 posted, Homework 3 Due  03/01/2021 or 03/02/2021 Week 8 (Lab 7) Week 7 computing in R ISLR: 8.3.3, 8.3.4 (RF and boosting), classification using NN   03/03/2021 Week 8 (Lecture 13) Clustering I ISLR: 10.3.1   03/05/2021 Week 8 (Lecture 14) Clustering II ISLR: 10.3.1   03/08/2021 or 03/09/2021 Week 9 (Lab 8) Week 8 computing in R    03/10/2021 Week 9 (Lecture 15) PCA ISLR: 10.2   03/12/2021 Week 9 (Lecture 16) Discriminant analysis I ISLR: 4.4.1, 4.4.2 Homework 5 posted, Homework 4 Due  03/15/2021 or 03/16/2021 Week 10 (Lab 9) Week 9 computing in R    03/17/2021 Week 10 (Lecture 17) Discriminant analysis II ISLR: 4.4.3, 4.4.4   03/19/2021 Week 10 (Lecture 18) Subset selection ISLR: 6.1   03/22/2021 or 03/23/2021 Week 11 (Lab 10) Week 10 computing in R    03/24/2021 Week 11 (Lecture 19) Penalized regression I ISLR: 2.2, 6.2.1   03/26/2021 Week 11 (Lecture 20) Penalized regression II ISLR: 6.2.2, 6.2.3 Homework 6 posted, Homework 5 Due  03/29/2021 or 03/30/2021 Week 12 (Lab 11) Week 11 computing in R    03/31/2021 Week 12 (Lecture 21) Logistic regression I ISLR: 4.3.1   04/02/2021    Good Friday: No classes or examinations  04/05/2021 or 04/06/2021 Week 13 (Lab 12) Week 12 computing in R    04/07/2021 Week 13 (Lecture 22) Logistic regression II ISLR: 4.3.2, 4.3.3   04/09/2021 Week 13 (Lecture 23) Sensitivity and specificity  Homework 6 Due  04/12/2021 or 04/13/2021 Week 14 (Lab 13) Week 13 computing in R    04/14/2021 Week 14 (Lecture 24) Wrap-up       R Markdown files Available upon request.\n  ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630900123,"objectID":"a770e2814a5a3064e736df1a43365d3c","permalink":"https://PratheepaJ.github.io/teaching/stats3ds3/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/teaching/stats3ds3/","section":"teaching","summary":"Intoduction to Data Science Theory.","tags":[],"title":"STATS 3DS3 (Winter 2021, McMaster)","type":"teaching"},{"authors":[],"categories":[],"content":"   Application Method Software Paper   The AR models are typically used to model the time series data. Several possible procedures exist for estimating model parameters. We refer to some of them as Yule-Walker (YW) estimators (Yule, 1927), least squares estimators, Burg estimators (Burg, 1968), and maximum likelihood estimators. Although the YW estimators produce bias in the estimation, this is a commonly used estimation method in practice.\nApplication Once the AR model is fit to the data, it is common to check the significance of model parameters. We then identify the order of the AR model.\n Method We derive the bivariate saddlepoint density approximation for the YW estimators of AR(2) model parameters. First, we write the sample autocorrelation as the ratio of quadratic forms. Then, we substitute this ratio in the YW equations and derive a system of quadratic estimating equations (QEE). Next, we show that the YW estimators of AR(2) model parameters are roots of QEE. We also show that the Jacobian of the transformation of the QEE coordinate space to the parameter coordinate space is positive semi-definite. Finally, we derive the bivariate saddlepoint density approximation using that of QEE.\n Software  PhD dissertation Chapter II supplement.   Paper  PhD dissertation Chapter II.   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630892209,"objectID":"0bbde617ef7e1061d52f7a99b1bd8bcd","permalink":"https://PratheepaJ.github.io/project/msap/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/msap/","section":"project","summary":"Estimating the joint density of Yule-Walker (YW) estimators by inverting the joint saddlepoint density of the YW estimating equations in an AR(2) model.","tags":[],"title":"Multivariate Saddlepoint Density Approximation (MSAP)","type":"project"},{"authors":[],"categories":[],"content":"   Description Syllabus  Course Overview Expected outcomes Course Information Prerequisites Textbook Software Evaluation  Lecture Notes  Course Schedule R Markdown files    Description Course link.\n Syllabus Course Overview Statistical tools for modern data analysis. Topics include regression and prediction, elements of the analysis of variance, bootstrap, and cross-validation. Emphasis is on conceptual rather than theoretical understanding. Student assignments require use of the software package R.\n Expected outcomes By the end of the course, students should be able to:\n Enter tabular data using R. Plot data using R, to help in exploratory data analysis. Formulate regression models for the data, while understanding some of the limitations and assumptions implicit in using these models. Fit models using R and interpret the output. Test for associations in a given model. Use diagnostic plots and tests to assess the adequacy of a particular model. Find confidence intervals for the effects of different explanatory variables in the model. Use some basic model selection procedures, as found in R, to find a best model in a class of models. Fit simple ANOVA models in R, treating them as special cases of multiple regression models. Fit simple logistic and Poisson regression models.   Course Information  Term: Autumn 2019 Units: 3    Prerequisites An introductory statistics course, such as - STATS 60 or STATS 110 or STATS 141.\n Textbook  Required:  (CH) Regression Analysis by Example.  Authors: Samprit Chatterjee, Ali S. Hadi Edition: \\(5^{th}\\) Edition Print ISBN:978-0-470-90584-05     Software  In this course, we will use R for computing and R Markdown for producing lecture slides, solutions for homework assignments. R Markdown is highly recommended to write the solutions for homework assignments. Install the following software:  R (required): https://www.r-project.org/. R Studio is highly recommended for syntax highlighting, package management, document generation, and more: https://www.rstudio.com/.  The newest version of R Studio is highly recommended.  LaTeX, which will enable you to create PDFs directly from the R Markdown in RStudio.     Evaluation The final letter grade for this course will be determined by each method of assessment weighted as follows:\n 7 weekly homework assignments (55%) Midterm examination (15%, Wednesday, 10/23/2019) Final examination (30%, according to Stanford calendar: Wednesday, 12/11/2019 @ 3:30 PM, location TBD)    Lecture Notes Course Schedule     Date Week Topic Reading Notes    09/23/2019 Week 1 Lecture 1 Course introduction and review Syllabus   09/25/2019 Week 1 Lecture 2 Review CH: 1   09/27/2019 Week 1 Lecture 3 Some tips on R  Homework 1 posted  09/30/2019 Week 2 Lecture 4 Simple linear regression 1 (introduction, correlation, model, estimation) CH: 2.1-2.4 –  10/02/2019 Week 2 Lecture 5 Simple linear regression 2 (inference and prediction) CH: Chapter 2.5-2.8 –  10/04/2019 Week 2 Lecture 6 Diagnostics for simple linear regression CH: 2.9 Homework 2 posted, Homework 1 Due  10/07/2019 Week 3 Lecture 7 Multiple linear regression 1 (introduction, model, estimation, geometry of least squares) CH: 3.1-3.5 –  10/09/2019 Week 3 Lecture 8 Multiple linear regression 2 (interpretation, matrix formulation, estimation, inference) CH: 3.6-3.9 –  10/11/2019 Week 3 Lecture 9 Multiple linear regression 3 (prediction, contrasts, testing) CH: 3.10-3.11 Homework 3 posted, Homework 2 Due  10/14/2019 Week 4 Lecture 10 Diagnostics in multiple linear regression (types of residuals, influence) CH: 4 –  10/16/2019 Week 4 Lecture 11 Diagnostics in multiple linear regression (outlier detection, residual plots) CH: 4 –  10/18/2019 Week 4 Lecture 12 Interactions and qualitative variables (interactions) CH: 5 Homework 4 posted, Homework 3 Due  10/21/2019 Week 5 Lecture 13 Interactions and qualitative variables (visualization, ANOVA) CH: 5 –  10/23/2019  – – Midterm Examinations  10/25/2019 Week 5 Lecture 14 ANOVA models (one-way ANOVA, testing, contrasts) CH: 5 –  10/28/2019 Week 6 Lecture 15 ANOVA models (two-way ANOVA, testing, contrasts, mixed effects model) CH: 5 –  10/30/2019 Week 6 Lecture 16 Transformations and Weighted Least Squares CH: 6,7 –  11/01/2019 Week 6 Lecture 17 Correlated errors CH: Chapter 8,9 Homework 5 posted, Homework 4 Due  11/04/2019 Week 7 Lecture 18 Correlated errors CH: Chapter 8,9 –  11/06/2019 Week 7 Lecture 19 Bootstrapping regression An Introduction to the Bootstrap by Bradley Efron, Robert Tibshirani, Chapter 9 –  11/08/2019 Week 7 Lecture 20 Model selection CH: 11 Homework 6 posted, Homework 5 Due  11/11/2019 Week 8 Lecture 21 Selection CH: 11 –  11/13/2019 Week 8 Lecture 22 Selection CH: 11 –  11/15/2019 Week 8 Lecture 23 Penalized regression CH: 10 Homework 7 posted, Homework 6 Due  11/18/2019 Week 9 Lecture 24 Penalized regression CH: 10 –  11/20/2019 Week 9 Lecture 25 Penalized regression CH: 10 –  11/22/2019 Week 9 Lecture 26 Logistic regression CH: 12 Homework 7 Due  11/25/2019 – – – Thanksgiving Recess (no classes)  11/27/2019 – – – Thanksgiving Recess (no classes)  11/29/2019 – – – Thanksgiving Recess (no classes)  12/02/2019 Week 10 Lecture 27 Logistic regression CH: 12 –  12/04/2019 Week 10 Lecture 28 Poisson regression CH: Chapter 13.3 –  12/06/2019 Week 10 Lecture 29 Final Review Review will be posted –  12/11/2019  – – End-Quarter examinations     R Markdown files R Markdown files to create the lecture slides and PDFs are available in https://github.com/PratheepaJ/STATS191.\n  ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630900007,"objectID":"77f6f41f31e8b4aebd0300fb0541f425","permalink":"https://PratheepaJ.github.io/teaching/stats191/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/teaching/stats191/","section":"teaching","summary":"Introduction to Applied Statistics.","tags":[],"title":"STATS 191 (Autumn 2019, Stanford)","type":"teaching"},{"authors":[],"categories":[],"content":"   Application Method Software Paper   We consider a class of statistical methods called the saddlepoint-based bootstrap (SPBB) method to make inferences about the spatial dependence parameter in the spatial regression model.\nApplication For example, in spatial econometrics, we can use the SPBB method to infer the significance of the spatial dependence parameter. We can use either the spatial autoregressive model, conditional autoregressive model, or spatial moving average models to fit the spatial lattice data.\n Method We use the SPBB method to construct confidence intervals for a parameter whose estimator is a unique root of a quadratic estimating equation. In the SPBB method, we use the monotonicity of the quadratic estimating equation in parameter to relate the distribution of an estimator to the distribution of the respective quadratic estimating equation. Using the saddlepoint methods, it is then possible to accurately approximate the distribution of the estimator. Then confidence interval can be produced by pivoting the distribution of the estimator.\n Software  R package SPBBspatial. Tutorial.   Paper  Available in Spatial statistics.\n Master thesis.\n   ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630888277,"objectID":"a28f2e135c3f5bad30c2f2e813d02c74","permalink":"https://PratheepaJ.github.io/project/spbb/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/project/spbb/","section":"project","summary":"Indirect inference about the spatial dependence parameter in the spatial regression model through estimating equation.","tags":[],"title":"Saddlepoint-Based Bootstrap Method (SPBB)","type":"project"},{"authors":[],"categories":[],"content":"   Description Syllabus  Course Overview Expected outcomes Course Information Prerequisites Texts Other sources Software Evaluation  Lecture Notes  Course Schedule R Markdown files    Description Course link.\n Syllabus Course Overview This course covers nonparametric analogs of the one- and two-sample t-tests and analysis of variance; the sign test, median test, Wilcoxon’s tests, and the Kruskal-Wallis and Friedman tests, tests of independence; nonparametric regression and nonparametric density estimation; modern nonparametric techniques; nonparametric confidence interval estimates.\n Expected outcomes By the end of the course, the student should be able to\n understand the assumptions underlying the nonparametric methods apply nonparametric methods to modern data analysis problems get hands-on experience in implementing methods and using existing R packages.   Course Information  Term: Spring 2019 Units: 3    Prerequisites  STATS 60 or STATS 110 or STATS 160; Students should familiar with summary statistics, hypothesis testing, point estimation, interval estimation (confidence intervals), basics of statistical inference, and R.   Texts  Required:  (HWC) Nonparametric Statistical Methods.  Authors: Myles Hollander, Douglas A. Wolfe, Eric Chicken Edition: \\(3^{rd}\\) Edition Print ISBN:9780470387375 Online ISBN:9781119196037   Recommended:  (DH): Davison and Hinkley (1997). Boostrap Method and Their Application. (ET): Efron and Tibshirani (1994). An Introduction to the Bootstrap. (KM): Kloke and McKean (2015). Nonparametric Statistical Methods Using R. (L): Lehmann (2006). Nonparametrics: Statistical Methods Based on Ranks. (RHG): Ramsay, Hooker, Graves (2009). Functional Data Analysis with R and MATLAB. (W): Wasserman (2006). All of Nonparametric Statistics.    Other sources  Recommended Readings: a reading list will be posted on Canvas.  Re:BHLLSW2009: Buja, Cook, Hofmann, Lawrence, Lee, Swayne, and Wickham (2009). Statistical Inference for Exploratory Data Analysis and Model Diagnostics. Re:D1983: Diaconis (1983). Theories of Data Analysis: From Magical Thinking Through Classical Statistics. Re:DH1994: Diaconis and Holmes (1994). Gray Codes for Randomization Procedures. Re:DH1995: Diaconis and Holmes (1995). Discrete Probability and Algorithms: Three Examples of Monte-Carlo Markov Chains: At the Interface Between Statistical Computing, Computer Science, and Statistical Mechanics, pg. 43-56. Re:JWH2014: Josse, Wager, and Husson (2014). Confidence Areas for Fixed-Effects PCA.  Useful links  Li:H1997: Holmes (1997). Lecture Notes on Computer Intensive Methods in Statistics. Li:H2004: Holmes (2004). Lecture Notes on Complete Enumeration. Li:C2016: Seiler (2016). Lecture Notes on Nonparametric Statistics. Li:W2016: Wasserman (2016). Lecture Notes on Nonparametric Bayesian Methods.    Software  In this course, we will use R for computing and R Markdown for producing lecture slides, solutions for homework assignments. R Markdown/Latex is highly recommended to write the midterm project proposal report and final project report. Install the following software:  R (required): https://www.r-project.org/. R Studio is highly recommended for syntax highlighting, package management, document generation, and more: https://www.rstudio.com/.  The newest version of R Studio is highly recommended (v1.1.463).  Latex, which will enable you to create PDFs directly from the R Markdown in RStudio.  Latex, which will enable you to create PDFs directly from the R Markdown in RStudio. Install Tinytex  install.packages(‘tinytex’) tinytex::install_tinytex()      Evaluation The final letter grade for this course will be determined by each method of assessment weighted as follows:\n Class participation (5%) Weekly homework assignments (50%) Midterm project proposal (10%, due on 05/03/2019) Final project (35%, due on 06/05/2019)    Lecture Notes Course Schedule     Date Week Topic Reading Notes    04/01/2019 Week 1 Lecture 0 Overview of current research in nonparametric and adequate initiation to R and R Markdown ASA Nonparametric statistics section news, install R, install RStudio; TryR, R Markdown webinar, R Markdown   04/03/2019 Week 1 Lecture 1 Logistics and Preliminaries HWC: 1   04/05/2019 Week 1 Lecture 2 The One-sample problem I (testing procedure) HWC: 3.4-3.6, 3.8, 3.1-3.3, 3.7 Homework 1 posted  04/08/2019 Week 2 Lecture 3 The One-sample problem II (estimator associated with the statistic, confidence interval, example) HWC: 3.4-3.6, 3.8, 3.1-3.3, 3.7   04/10/2019 Week 2 Lecture 4 Statistical functionals and Influence functions W: 2, ET: 4, 5, 21.3   04/12/2019 Week 2 Lecture 5 Jackknife and Bootstrap I HWC: 8.4, W: 3, DH, ET: 6, 11 Homework 2 Posted, Homework 1 Due  04/15/2019 Week 3 Lecture 6 Bootstrap II ET: 23, Re:DH1994, Re:DH1995   04/17/2019 Week 3 Lecture 7 Discrete data problems I HWC: 2   04/19/2019 Week 3 Lecture 8 Discrete data problems II HWC: 10 Homework 3 Posted, Homework 2 Due  04/22/2019 Week 4 Lecture 9 Two-sample problem I HWC: 4   04/24/2019 Week 4 Lecture 10 Two-sample problem II HWC: 5   04/26/2019 Week 4 Lecture 11 Permutation Test I ET: 15, Li:H1997 Homework 4 Posted, Homework 3 Due  04/29/2019 Week 5 Lecture 12 Permutation Test II Li:H1997, Li:C2016   05/01/2019 Week 5 Lecture 13 Ranked-based linear regression HWC: 9   05/03/2019 Week 5 Lecture 14 Smoothing I W: 4 Midterm project proposal due  05/06/2019 Week 6 Lecture 15 Nonparametric regression I HWC: 9.7, 14, W: Chapter 5   05/08/2019 Week 6 Lecture 16 Nonparametric regression II HWC: 9.7, 14, W: Chapter 5   05/10/2019 Week 6 Lecture 17 Wavelets HWC: 13, W: Chapter 9 Homework 5 Posted, Homework 4 Due  05/13/2019 Week 7 Lecture 18 ANOVA I HWC: 6, 7   05/15/2019 Week 7 Lecture 19 ANOVA II , multiple comparison HWC: 6, 7   05/17/2019 Week 7 Survival analysis I HWC: 10 Homework 6 Posted, Homework 5 Due  05/20/2019 Week 8 Survival analysis II HWC: Chapter 10   05/22/2019 Week 8 Ranked set sampling HWC: 15   05/24/2019 Week 8 Bayesian nonparametric I HWC: Chapter 16, Li:W2016 Homework 7 Posted, Homework 6 Due  05/27/2019 Week 9 (Holiday, no classes)  Memorial Day  05/29/2019 Week 9 Bayesian nonparametric II HWC: 16, Li:W2016   05/31/2019 Week 9 Lecture 25 Inference for data visualization Re:BHLLSW2009, Re:D1983, Re:JWH2014 Homework 7 Due (no late submission allowed, End-Quarter Period starts)  06/03/2019 Week 10 Lecture 26 Bootstrap III ET: 12, 14   06/05/2019 Week 10 Lecture 27 Wrap-up  Final project due     R Markdown files R Markdown files to create the lecture slides and PDFs are available in https://github.com/PratheepaJ/STATS205.\n  ","date":1630800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630899855,"objectID":"3e74ea22faaffd7ce48dccfb01342319","permalink":"https://PratheepaJ.github.io/teaching/stats205/","publishdate":"2021-09-05T00:00:00Z","relpermalink":"/teaching/stats205/","section":"teaching","summary":"Introduction to Nonparametric Statistics.","tags":[],"title":"STATS 205 (Spring 2019, Stanford)","type":"teaching"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://PratheepaJ.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fba6c149775da15c6a5b2adae893dd1c","permalink":"https://PratheepaJ.github.io/joinus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/joinus/","section":"","summary":"Join Jeganathan research group at McMaster University","tags":null,"title":"Join Us","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6e7e6c64a47fc68754e543944bd2c2ab","permalink":"https://PratheepaJ.github.io/researchgroup/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/researchgroup/","section":"","summary":"People at Jeganathan's research group","tags":null,"title":"Research group","type":"widget_page"}]